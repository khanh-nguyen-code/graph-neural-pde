import argparse
import torch
import numpy as np
import os
from GNN_image_pixel import GNN_image_pixel
from torch_geometric.data import DataLoader
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from torch_geometric.utils import to_dense_adj
import pandas as pd
from data_image import load_pixel_data
import shutil
from MNIST_SuperPix import load_SuperPixel_data, transform_objects, get_centroid_coords_array
import skimage
from skimage.segmentation import slic
from skimage.color import label2rgb
from skimage import segmentation
import networkx as nx
from torch_geometric.utils.convert import to_networkx


def UnNormalizeCIFAR(data):
  #normalises each image channel to range [0,1] from [-1, 1]
  # return (data - torch.amin(data,dim=(0,1))) / (torch.amax(data,dim=(0,1)) - torch.amin(data,dim=(0,1)))
  return data * 0.5 + 0.5

def check_folder(savefolder):
  try:
    os.mkdir(savefolder)
  except OSError:
    if os.path.exists(savefolder):
      shutil.rmtree(savefolder)
      os.mkdir(savefolder)
      print("%s exists, clearing existing images" % savefolder)
    else:
      print("Creation of the directory %s failed" % savefolder)
  else:
    print("Successfully created the directory %s " % savefolder)


def plot_T0(out, num_centroids, SuperPixItem, r_x_coords, r_y_coords, paths, atts,
            NXgraph, r_centroids, modelfolder, batch_idx, weight_max):
  fig, ax = plt.subplots()
  ax.axis('off')
  ax.imshow(out)
  for i in range(num_centroids):
    label = SuperPixItem.y[i].item()
    ax.annotate(label, (r_x_coords[i], r_y_coords[i]), c="red")
  ax.scatter(x=r_x_coords, y=r_y_coords)
  time = 0
  x = paths[:, time, :].detach().numpy()
  edge_weights = atts[time].detach().numpy()
  edge_weights = ((edge_weights - edge_weights.min()) / (edge_weights.max() - edge_weights.min())) * (
          weight_max - 1) + 1
  nx.draw(NXgraph, r_centroids, ax=ax, node_size=300 / 4, edge_color=list(edge_weights),  # "lime",
          node_color=x, cmap=plt.get_cmap('Spectral'), width=list(edge_weights))
  plt.title(f"t={time} Attention, Ground Truth: {SuperPixItem.target.item()}")
  plt.savefig(f"{modelfolder}/sample_{batch_idx}/initial_{time}.pdf", format="pdf")
  plt.show()

def plot_diffusion(paths, pixel_labels, im_height, im_width, heightSF, widthSF, centroids,
                   num_centroids, atts, weight_max, NXgraph, SuperPixItem, modelfolder, batch_idx, times):
  for time in times:
    x = paths[:, time, :].detach().numpy()
    broadcast_pixels = x[pixel_labels].squeeze()
    r_pixel_values, r_pixel_labels, r_centroids = transform_objects(im_height, im_width, heightSF, widthSF,
                                                                    broadcast_pixels, pixel_labels.numpy(), centroids)
    r_y_coords, r_x_coords = get_centroid_coords_array(num_centroids, r_centroids)
    r_pixel_labels = r_pixel_labels.astype(np.int)
    out = segmentation.mark_boundaries(r_pixel_values, r_pixel_labels, (1, 0, 0))

    fig, ax = plt.subplots()
    ax.axis('off')
    ax.imshow(out)
    for i in range(num_centroids):
      prediction = round(x[i].item(), 2)
      ax.annotate(prediction, (r_x_coords[i], r_y_coords[i]), c="red")
    ax.scatter(x=r_x_coords, y=r_y_coords)
    edge_weights = atts[time].detach().numpy()
    edge_weights = ((edge_weights - edge_weights.min()) / (edge_weights.max() - edge_weights.min())) \
                   * (weight_max - 1) + 1
    nx.draw(NXgraph, r_centroids, ax=ax, node_size=300 / 4, edge_color=list(edge_weights),  # "lime",
            node_color=x, cmap=plt.get_cmap('Spectral'), width=list(edge_weights))

    plt.title(f"t={time} Attention, Ground Truth: {SuperPixItem.target.item()}")
    plt.savefig(f"{modelfolder}/sample_{batch_idx}/diffused_{time}.pdf", format="pdf")
    plt.show()
  # return fig


def plot_deltas(paths, pixel_labels, im_height, im_width, heightSF, widthSF, centroids,
                   num_centroids, atts, weight_max, NXgraph, SuperPixItem, modelfolder, batch_idx, times):
  for time in times:
    # x = paths[:, time, :].detach().numpy()
    x = paths[:, time+1, :].detach().numpy() - paths[:, time, :].detach().numpy()
    broadcast_pixels = x[pixel_labels].squeeze()
    r_pixel_values, r_pixel_labels, r_centroids = transform_objects(im_height, im_width, heightSF, widthSF,
                                                                    broadcast_pixels, pixel_labels.numpy(), centroids)
    r_y_coords, r_x_coords = get_centroid_coords_array(num_centroids, r_centroids)
    r_pixel_labels = r_pixel_labels.astype(np.int)
    out = segmentation.mark_boundaries(r_pixel_values, r_pixel_labels, (1, 0, 0))

    fig, ax = plt.subplots()
    ax.axis('off')
    ax.imshow(out)
    for i in range(num_centroids):
      prediction = round(x[i].item(), 2)
      ax.annotate(prediction, (r_x_coords[i], r_y_coords[i]), c="red")
    ax.scatter(x=r_x_coords, y=r_y_coords)
    # edge_weights = atts[time].detach().numpy()
    edge_weights = atts[time+1].detach().numpy() - atts[time].detach().numpy()

    edge_weights = ((edge_weights - edge_weights.min()) / (edge_weights.max() - edge_weights.min())) \
                   * (weight_max - 1) + 1
    nx.draw(NXgraph, r_centroids, ax=ax, node_size=300 / 4, edge_color=list(edge_weights),  # "lime",
            node_color=x, cmap=plt.get_cmap('Spectral'), width=list(edge_weights))

    plt.title(f"t={time} Attention, Ground Truth: {SuperPixItem.target.item()}")
    plt.savefig(f"{modelfolder}/sample_{batch_idx}/delta_{time}.pdf", format="pdf")
    plt.show()


def save_attention_matrices(SuperPixItem, atts, times, num_centroids, modelfolder, batch_idx):
  for time in times:
    dense_att = to_dense_adj(edge_index=SuperPixItem.edge_index, edge_attr=atts[time].detach(),
                             max_num_nodes=num_centroids)[0, :, :]
    square_att = dense_att.view(num_centroids, num_centroids)
    x_np = square_att.detach().numpy()
    x_df = pd.DataFrame(x_np)
    x_df.to_csv(f"{modelfolder}/sample_{batch_idx}/att_{time}.csv")

# def plot_attention_paths(atts, modelfolder):
#   atts = torch.stack(atts,dim=1).detach().numpy().T
#   fig = plt.figure()
#   plt.tight_layout()
#   plt.plot(atts)
#   plt.title("Attentions Evolution")
#   plt.savefig(f"{modelfolder}/atts_evol.pdf", format="pdf")
#   plt.show()

def plot_max_min_pix_intensity(paths, SuperPixItem, modelfolder, batch_idx):
  fig = plt.figure()
  plt.tight_layout()
  A = paths[:, :, 0].detach().cpu()
  plt.plot(torch.max(A, dim=0)[0], color='red')
  plt.plot(torch.min(A, dim=0)[0], color='green')
  plt.plot(torch.mean(A, dim=0), color='blue')
  plt.title("Max/Min, Ground Truth: {}".format(SuperPixItem.target.item()))
  plt.savefig(f"{modelfolder}/sample_{batch_idx}/max_min.pdf", format="pdf")
  plt.show()

def create_animation(paths, atts, pixel_labels, NXgraph, SuperPixItem, im_height, im_width,
                     heightSF, widthSF, centroids, num_centroids, weight_max, modelfolder, batch_idx):
  # draw initial graph
  time = 0
  x = paths[:, time, :].detach().numpy()
  broadcast_pixels = x[pixel_labels].squeeze()
  r_pixel_values, r_pixel_labels, r_centroids = transform_objects(im_height, im_width, heightSF, widthSF,
                                                                  broadcast_pixels, pixel_labels.numpy(), centroids)
  r_y_coords, r_x_coords = get_centroid_coords_array(num_centroids, r_centroids)
  r_pixel_labels = r_pixel_labels.astype(np.int)
  out = segmentation.mark_boundaries(r_pixel_values, r_pixel_labels, (1, 0, 0))

  fig, ax = plt.subplots()
  ax.axis('off')
  ax.imshow(out)
  for i in range(num_centroids):
    ax.annotate(i, (r_x_coords[i], r_y_coords[i]), c="red")
  ax.scatter(x=r_x_coords, y=r_y_coords)
  edge_weights = atts[time].detach().numpy()  # * (x[SuperPixItem.edge_index[0,:]].squeeze()
  #  + x[SuperPixItem.edge_index[1,:]].squeeze())
  edge_weights = ((edge_weights - edge_weights.min()) / (edge_weights.max() - edge_weights.min())) * (
            weight_max - 1) + 1

  nx.draw(NXgraph, r_centroids, ax=ax, node_size=300 / 4, edge_color=list(edge_weights),  # "lime",
          node_color=x, cmap=plt.get_cmap('Spectral'), width=list(edge_weights))
  plt.title(f"t={time} Attention, Ground Truth: {SuperPixItem.target.item()}")

  # loop through data and update plot
  def update(ii):
    plt.tight_layout()
    x = paths[:, ii, :].detach().numpy()
    broadcast_pixels = x[pixel_labels].squeeze()
    r_pixel_values, r_pixel_labels, r_centroids = transform_objects(im_height, im_width, heightSF, widthSF,
                                                                    broadcast_pixels, pixel_labels.numpy(), centroids)
    r_y_coords, r_x_coords = get_centroid_coords_array(num_centroids, r_centroids)
    r_pixel_labels = r_pixel_labels.astype(np.int)
    out = segmentation.mark_boundaries(r_pixel_values, r_pixel_labels, (1, 0, 0))
    ax.imshow(out)
    for i in range(num_centroids):
      ax.annotate(i, (r_x_coords[i], r_y_coords[i]), c="red")
    ax.scatter(x=r_x_coords, y=r_y_coords)
    edge_weights = atts[ii].detach().numpy()  # * (x[SuperPixItem.edge_index[0,:]].squeeze()
    #    + x[SuperPixItem.edge_index[1,:]].squeeze())
    edge_weights = ((edge_weights - edge_weights.min()) / (edge_weights.max() - edge_weights.min())) * (
              weight_max - 1) + 1

    nx.draw(NXgraph, r_centroids, ax=ax, node_size=300 / 4, edge_color=list(edge_weights),  # "lime",
            node_color=x, cmap=plt.get_cmap('Spectral'), width=list(edge_weights))
    plt.title(f"t={ii} Attention, Ground Truth: {SuperPixItem.target.item()}")

  fig = plt.gcf()
  frames = 10
  fps = 1.5
  animation = FuncAnimation(fig, func=update, frames=frames)
  animation.save(f"{modelfolder}/sample_{batch_idx}/animation.gif",
                 fps=fps)  # , writer='imagemagick', savefig_kwargs={'facecolor': 'white'}, fps=fps)


def plot_attention_evolution(attention_epochs, model, batch_idx, batch, modelfolder, model_key, device, Tmultiple, partitions):
    for att_epoch in attention_epochs:
      modelpath = f"{modelfolder}/model_{model_key}_epoch{att_epoch}"
      model.load_state_dict(torch.load(f"{modelpath}.pt", map_location=device))
      model.to(device)
      model.eval()
      paths, atts = model.forward_plot_SuperPix(batch.x.to(model.device), Tmultiple * partitions)

      # plot attention paths
      atts = torch.stack(atts, dim=1).detach().T
      fig = plt.figure()
      plt.tight_layout()
      plt.plot(atts)
      plt.title("Attentions Evolution")
      plt.savefig(f"{modelfolder}/sample_{batch_idx}/atts_evol_epoch{att_epoch}.pdf", format="pdf")
      # plt.show()


def build_batches(model_keys, model_epochs, attention_epochs, samples, Tmultiple, partitions, batch_num, times):
  directory = f"../SuperPix/"
  df = pd.read_csv(f'{directory}models.csv')
  for i, model_key in enumerate(model_keys):
    for filename in os.listdir(directory):
      if filename.startswith(model_key):
        path = os.path.join(directory, filename)
        print(path)
        break
    [_, _, data_name, blck, fct] = path.split("_")
    modelfolder = f"{directory}{model_key}_{data_name}_{blck}_{fct}"
    modelpath = f"{modelfolder}/model_{model_key}_epoch{model_epochs[i]}"
    optdf = df[df.model_key == model_key]
    intcols = ['num_class','im_chan','im_height','im_width','num_nodes']
    optdf[intcols].astype(int)
    opt = optdf.to_dict('records')[0]
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    SuperPixelData = load_SuperPixel_data(opt)
    loader = DataLoader(SuperPixelData, batch_size=1, shuffle=False)  # True)
    opt['time'] = opt['time'] / partitions
    for batch_idx, batch in enumerate(loader):
      if batch_idx == samples:
        break
      batch.to(device)
      edge_index_gpu = batch.edge_index
      edge_attr_gpu = batch.edge_attr
      if edge_index_gpu is not None: edge_index_gpu.to(device)
      if edge_attr_gpu is not None: edge_index_gpu.to(device)

      model = GNN_image_pixel(opt, batch.num_features, batch.num_nodes, opt['num_class'], edge_index_gpu,
                              edge_attr_gpu, device).to(device)

      model.load_state_dict(torch.load(f"{modelpath}.pt", map_location=device))
      model.to(device)
      model.eval()
      paths, atts = model.forward_plot_SuperPix(batch.x.to(model.device), Tmultiple * partitions)
      SuperPixItem = batch

      im_height = opt['im_height']
      im_width = opt['im_width']
      SF = 448  # 56 #480  # 480    #RESIZING needed as mark_boundaries marks 1 pixel wide either side of boundary
      heightSF = SF / im_height
      widthSF = SF / im_width

      pixel_values = SuperPixItem.orig_image.detach().numpy()
      pixel_labels = SuperPixItem.pixel_labels.view(im_height, im_width)
      x = SuperPixItem.x
      broadcast_pixels = x[pixel_labels].squeeze().numpy()
      centroids = SuperPixItem.centroids[0]
      num_centroids = torch.max(pixel_labels) + 1
      r_pixel_values, r_pixel_labels, r_centroids = transform_objects(im_height, im_width, heightSF, widthSF,
                                                                      pixel_values, pixel_labels.numpy(), centroids)
      r_y_coords, r_x_coords = get_centroid_coords_array(num_centroids, r_centroids)
      r_pixel_labels = r_pixel_labels.astype(np.int)
      out = segmentation.mark_boundaries(r_pixel_values, r_pixel_labels, (1, 0, 0))
      weight_max = 5
      NXgraph = to_networkx(SuperPixItem)

      check_folder(f"{modelfolder}/sample_{batch_idx}")
      #####PLOT DIFFUSIONS
      plot_diffusion(paths, pixel_labels, im_height, im_width, heightSF, widthSF, centroids,
                     num_centroids, atts, weight_max, NXgraph, SuperPixItem, modelfolder, batch_idx, times)
      #####save down attention matrices
      save_attention_matrices(SuperPixItem, atts, times, num_centroids, modelfolder, batch_idx)
      #####plot attention paths
      # plot_attention_paths(atts, modelfolder)
      ####Plot max/min pixel intensity
      plot_max_min_pix_intensity(paths, SuperPixItem, modelfolder, batch_idx)
      ###### CREATE ANIMATION

      # create_animation(paths, atts, pixel_labels, NXgraph, SuperPixItem, im_height, im_width,
      #                  heightSF, widthSF, centroids, num_centroids, weight_max, modelfolder, batch_idx)

      ###### CREATE attention_evolution
      plot_attention_evolution(attention_epochs, model, batch_idx, batch, modelfolder, model_key, device,
                          Tmultiple, partitions)
      #####PLOT T=0 before diffusion
      plot_T0(out, num_centroids, SuperPixItem, r_x_coords, r_y_coords, paths, atts,
              NXgraph, r_centroids, modelfolder, batch_idx, weight_max)


@torch.no_grad()
def model_comparison(model_keys, model_epochs, times, image_folder, samples, Tmultiple, partitions, batch_num):
    directory = f"../SuperPix/"
    df = pd.read_csv(f'{directory}models.csv')
    savefolder = f"../SuperPix/images/{image_folder}"
    check_folder(savefolder)

    for sample in range(samples):
      region = 0 #330
      # fig, axs = plt.subplots(3,3, figsize=(9, 6), sharex=True, sharey=True)
      # fig, axs = plt.subplots(3,3,figsize=(14,14), sharex=True, sharey=True)
      fig, axs = plt.subplots(3,4,figsize=(14,14),
                              gridspec_kw={
                                'width_ratios': [1, 4, 4, 4],
                                'height_ratios': [1, 1, 1]},
                               sharex=True, sharey=True)

      # fig.suptitle(f"Model Comparison for SuperPixel Diffusion", size=24)#'x-large')

      label_list = []
      ###LOAD THE MODEL LOAD THE BATCH, GET PATHS AND ATTS
      for i, model_key in enumerate(model_keys):
        for filename in os.listdir(directory):
          if filename.startswith(model_key):
            path = os.path.join(directory, filename)
            print(path)
            break
        [_, _, data_name, blck, fct] = path.split("_")
        modelfolder = f"{directory}{model_key}_{data_name}_{blck}_{fct}"
        modelpath = f"{modelfolder}/model_{model_key}_epoch{model_epochs[i]}"
        optdf = df[df.model_key == model_key]
        intcols = ['num_class', 'im_chan', 'im_height', 'im_width', 'num_nodes']
        optdf[intcols].astype(int)
        opt = optdf.to_dict('records')[0]
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        SuperPixelData = load_SuperPixel_data(opt)
        loader = DataLoader(SuperPixelData, batch_size=1, shuffle=False)  # True)
        opt['time'] = opt['time'] / partitions

        label_list.append(f"{opt['block']}\n{opt['function']}")

        for batch_idx, batch in enumerate(loader):
          if batch_idx == sample:
            break
        batch.to(device)
        edge_index_gpu = batch.edge_index
        edge_attr_gpu = batch.edge_attr
        if edge_index_gpu is not None: edge_index_gpu.to(device)
        if edge_attr_gpu is not None: edge_index_gpu.to(device)

        model = GNN_image_pixel(opt, batch.num_features, batch.num_nodes, opt['num_class'], edge_index_gpu,
                                edge_attr_gpu, device).to(device)

        model.load_state_dict(torch.load(f"{modelpath}.pt", map_location=device))
        model.to(device)
        model.eval()
        paths, atts = model.forward_plot_SuperPix(batch.x.to(model.device), Tmultiple * partitions)


        ####GENERATE NECCESSARIES FOR THE PLOT
        SuperPixItem = batch
        im_height = opt['im_height']
        im_width = opt['im_width']
        SF = 448  # 56 #480  # 480    #RESIZING needed as mark_boundaries marks 1 pixel wide either side of boundary
        heightSF = SF / im_height
        widthSF = SF / im_width

        pixel_values = SuperPixItem.orig_image.detach().numpy()
        pixel_labels = SuperPixItem.pixel_labels.view(im_height, im_width)
        x = SuperPixItem.x
        broadcast_pixels = x[pixel_labels].squeeze().numpy()
        centroids = SuperPixItem.centroids[0]
        num_centroids = torch.max(pixel_labels) + 1
        r_pixel_values, r_pixel_labels, r_centroids = transform_objects(im_height, im_width, heightSF, widthSF,
                                                                        pixel_values, pixel_labels.numpy(), centroids)
        r_y_coords, r_x_coords = get_centroid_coords_array(num_centroids, r_centroids)
        r_pixel_labels = r_pixel_labels.astype(np.int)
        out = segmentation.mark_boundaries(r_pixel_values, r_pixel_labels, (1, 0, 0))
        weight_max = 5
        NXgraph = to_networkx(SuperPixItem)


        for time in times:
          if region in [0,4,8]:
            region += 1

          print(f"region {region} {region//3} {region%3}")
          ax = axs[region//4][region%4]#3]
          region += 1

          x = paths[:, time, :].detach().numpy()
          broadcast_pixels = x[pixel_labels].squeeze()
          r_pixel_values, r_pixel_labels, r_centroids = transform_objects(im_height, im_width, heightSF, widthSF,
                                                                          broadcast_pixels, pixel_labels.numpy(),
                                                                          centroids)
          r_y_coords, r_x_coords = get_centroid_coords_array(num_centroids, r_centroids)
          r_pixel_labels = r_pixel_labels.astype(np.int)
          out = segmentation.mark_boundaries(r_pixel_values, r_pixel_labels, (1, 0, 0))

          ax.axis('off')
          ax.imshow(out)
          # for i in range(num_centroids):
          #   prediction = round(x[i].item(), 2)
          #   ax.annotate(prediction, (r_x_coords[i], r_y_coords[i]), c="red")
          ax.scatter(x=r_x_coords, y=r_y_coords)
          edge_weights = atts[time].detach().numpy()
          edge_weights = ((edge_weights - edge_weights.min()) / (edge_weights.max() - edge_weights.min())) \
                         * (weight_max - 1) + 1
          nx.draw(NXgraph, r_centroids, ax=ax, node_size=300 / 4, edge_color=list(edge_weights),  # "lime",
                  node_color=x, cmap=plt.get_cmap('Spectral'), width=list(edge_weights))

      plt.subplots_adjust(wspace=-0.1, hspace=-0.1)
      # plt.subplots_adjust(left=0.2, right=1, bottom=0.1, top=0.95, wspace=-0.1, hspace=0.0)

      new_label_dict = {f"constant\nlaplacian" : f"Laplacian",
                     f"attention\nlaplacian": f"GRAND-l",
                     f"constant\ntransformer": f"GRAND-nl"}
      new_label_list = [new_label_dict[label] for label in label_list]
      plot_times = [f"t={round(opt['time'] * time,1)}" for time in times]
      plot_times = [""] + plot_times
      for ax, t in zip(axs[0], plot_times):
          ax.set_title(t, size=18)

      # pad = 2
      # for ax, row in zip(axs[:,0], new_label_list):
          # ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),
          #             xycoords=ax.yaxis.label, textcoords='offset points',
          #             size='large', ha='right', va='center')
          # ax.set_ylabel(row, rotation=0, size='medium')
      # axs[0,0].set(ylabel="a")
      # axs[1,0].set(ylabel="b")
      # axs[2,0].set(ylabel="c")
      axs[0,0].axis('off')
      axs[1,0].axis('off')
      axs[2,0].axis('off')
      axs[0,0].text(0.5, 0.5, new_label_list[0], horizontalalignment='center', verticalalignment='center',
               transform=axs[0,0].transAxes, rotation=90, size=20)
      axs[1,0].text(0.5, 0.5, new_label_list[1], horizontalalignment='center', verticalalignment='center',
               transform=axs[1,0].transAxes, rotation=90, size=20)
      axs[2,0].text(0.5, 0.5, new_label_list[2], horizontalalignment='center', verticalalignment='center',
               transform=axs[2,0].transAxes, rotation=90, size=20)

      plt.tight_layout()
      plt.ylabel("Please any give me any label")
      plt.savefig(f"{savefolder}/sample_{sample}.pdf",format="pdf")


@torch.no_grad()
def model_delta_comparison(model_keys, model_epochs, times, image_folder, samples, Tmultiple, partitions, batch_num):
    directory = f"../SuperPix/"
    df = pd.read_csv(f'{directory}models.csv')
    savefolder = f"../SuperPix/images/{image_folder}"
    # check_folder(savefolder)

    for sample in range(samples):
      region = 0 #330
      # fig, axs = plt.subplots(3,3, figsize=(9, 6), sharex=True, sharey=True)
      # fig, axs = plt.subplots(3,3,figsize=(14,14), sharex=True, sharey=True)
      fig, axs = plt.subplots(3,4,figsize=(14,14),
                              gridspec_kw={
                                'width_ratios': [1, 4, 4, 4],
                                'height_ratios': [1, 1, 1]},
                               sharex=True, sharey=True)

      # fig.suptitle(f"Model Comparison for SuperPixel Diffusion", size=24)#'x-large')

      label_list = []
      ###LOAD THE MODEL LOAD THE BATCH, GET PATHS AND ATTS
      for i, model_key in enumerate(model_keys):
        for filename in os.listdir(directory):
          if filename.startswith(model_key):
            path = os.path.join(directory, filename)
            print(path)
            break
        [_, _, data_name, blck, fct] = path.split("_")
        modelfolder = f"{directory}{model_key}_{data_name}_{blck}_{fct}"
        modelpath = f"{modelfolder}/model_{model_key}_epoch{model_epochs[i]}"
        optdf = df[df.model_key == model_key]
        intcols = ['num_class', 'im_chan', 'im_height', 'im_width', 'num_nodes']
        optdf[intcols].astype(int)
        opt = optdf.to_dict('records')[0]
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        SuperPixelData = load_SuperPixel_data(opt)
        loader = DataLoader(SuperPixelData, batch_size=1, shuffle=False)  # True)
        opt['time'] = opt['time'] / partitions

        label_list.append(f"{opt['block']}\n{opt['function']}")

        for batch_idx, batch in enumerate(loader):
          if batch_idx == sample:
            break
        batch.to(device)
        edge_index_gpu = batch.edge_index
        edge_attr_gpu = batch.edge_attr
        if edge_index_gpu is not None: edge_index_gpu.to(device)
        if edge_attr_gpu is not None: edge_index_gpu.to(device)

        model = GNN_image_pixel(opt, batch.num_features, batch.num_nodes, opt['num_class'], edge_index_gpu,
                                edge_attr_gpu, device).to(device)

        model.load_state_dict(torch.load(f"{modelpath}.pt", map_location=device))
        model.to(device)
        model.eval()
        paths, atts = model.forward_plot_SuperPix(batch.x.to(model.device), Tmultiple * partitions)


        ####GENERATE NECCESSARIES FOR THE PLOT
        SuperPixItem = batch
        im_height = opt['im_height']
        im_width = opt['im_width']
        SF = 448  # 56 #480  # 480    #RESIZING needed as mark_boundaries marks 1 pixel wide either side of boundary
        heightSF = SF / im_height
        widthSF = SF / im_width

        pixel_values = SuperPixItem.orig_image.detach().numpy()
        pixel_labels = SuperPixItem.pixel_labels.view(im_height, im_width)
        x = SuperPixItem.x
        broadcast_pixels = x[pixel_labels].squeeze().numpy()
        centroids = SuperPixItem.centroids[0]
        num_centroids = torch.max(pixel_labels) + 1
        r_pixel_values, r_pixel_labels, r_centroids = transform_objects(im_height, im_width, heightSF, widthSF,
                                                                        pixel_values, pixel_labels.numpy(), centroids)
        r_y_coords, r_x_coords = get_centroid_coords_array(num_centroids, r_centroids)
        r_pixel_labels = r_pixel_labels.astype(np.int)
        out = segmentation.mark_boundaries(r_pixel_values, r_pixel_labels, (1, 0, 0))
        weight_max = 5
        NXgraph = to_networkx(SuperPixItem)

        for time in times:
          if region in [0,4,8]:
            region += 1

          print(f"region {region} {region//3} {region%3}")
          ax = axs[region//4][region%4]#3]
          region += 1
          # x = paths[:, time, :].detach().numpy()
          x = paths[:, time+1, :].detach().numpy() - paths[:, time, :].detach().numpy()
          broadcast_pixels = x[pixel_labels].squeeze()
          r_pixel_values, r_pixel_labels, r_centroids = transform_objects(im_height, im_width, heightSF, widthSF,
                                                                          broadcast_pixels, pixel_labels.numpy(),
                                                                          centroids)
          r_y_coords, r_x_coords = get_centroid_coords_array(num_centroids, r_centroids)
          r_pixel_labels = r_pixel_labels.astype(np.int)
          out = segmentation.mark_boundaries(r_pixel_values, r_pixel_labels, (1, 0, 0))

          ax.axis('off')
          ax.imshow(out)
          # for i in range(num_centroids):
          #   prediction = round(x[i].item(), 2)
          #   ax.annotate(prediction, (r_x_coords[i], r_y_coords[i]), c="red")
          ax.scatter(x=r_x_coords, y=r_y_coords)
          # edge_weights = atts[time].detach().numpy()
          edge_weights = atts[time+1].detach().numpy() - atts[time].detach().numpy()

          edge_weights = ((edge_weights - edge_weights.min()) / (edge_weights.max() - edge_weights.min())) \
                         * (weight_max - 1) + 1
          nx.draw(NXgraph, r_centroids, ax=ax, node_size=300 / 4, edge_color=list(edge_weights),  # "lime",
                  node_color=x, cmap=plt.get_cmap('Spectral'), width=list(edge_weights))

      plt.subplots_adjust(wspace=-0.1, hspace=-0.1)
      # plt.subplots_adjust(left=0.2, right=1, bottom=0.1, top=0.95, wspace=-0.1, hspace=0.0)

      new_label_dict = {f"constant\nlaplacian" : f"Laplacian",
                     f"attention\nlaplacian": f"GRAND-l",
                     f"constant\ntransformer": f"GRAND-nl"}
      new_label_list = [new_label_dict[label] for label in label_list]
      plot_times = [f"t={round(opt['time'] * time,1)}" for time in times]
      plot_times = [""] + plot_times
      for ax, t in zip(axs[0], plot_times):
          ax.set_title(t, size=18)

      # pad = 2
      # for ax, row in zip(axs[:,0], new_label_list):
          # ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),
          #             xycoords=ax.yaxis.label, textcoords='offset points',
          #             size='large', ha='right', va='center')
          # ax.set_ylabel(row, rotation=0, size='medium')
      # axs[0,0].set(ylabel="a")
      # axs[1,0].set(ylabel="b")
      # axs[2,0].set(ylabel="c")
      axs[0,0].axis('off')
      axs[1,0].axis('off')
      axs[2,0].axis('off')
      axs[0,0].text(0.5, 0.5, new_label_list[0], horizontalalignment='center', verticalalignment='center',
               transform=axs[0,0].transAxes, rotation=90, size=20)
      axs[1,0].text(0.5, 0.5, new_label_list[1], horizontalalignment='center', verticalalignment='center',
               transform=axs[1,0].transAxes, rotation=90, size=20)
      axs[2,0].text(0.5, 0.5, new_label_list[2], horizontalalignment='center', verticalalignment='center',
               transform=axs[2,0].transAxes, rotation=90, size=20)

      plt.tight_layout()
      plt.ylabel("Please any give me any label")
      plt.savefig(f"{savefolder}/delta_sample_{sample}.pdf",format="pdf")


def find_best_epoch(model_keys):
  directory = f"../SuperPix/"
  df = pd.read_csv(f'{directory}models.csv')
  best_epochs = []
  for i, model_key in enumerate(model_keys):
    for filename in os.listdir(directory):
      if filename.startswith(model_key):
        path = os.path.join(directory, filename)
        print(path)
        break
    [_, _, data_name, blck, fct] = path.split("_")
    modelfolder = f"{directory}{model_key}_{data_name}_{blck}_{fct}"
    optdf = df[df.model_key == model_key]
    intcols = ['num_class', 'im_chan', 'im_height', 'im_width', 'num_nodes']
    optdf[intcols].astype(int)
    opt = optdf.to_dict('records')[0]

    test_acc_df = pd.read_csv(f'{modelfolder}/test_acc.csv')
    batch_per_epoch = opt['train_size'] / opt['batch_size']

    test_acc_df = test_acc_df[(test_acc_df.index + 1) % batch_per_epoch == 0]
    test_acc_df.idxmax(axis=0)
    best_epoch = int((test_acc_df['test_acc'].idxmax() + 1) / batch_per_epoch)
    # print(test_acc_df['test_acc'].idxmax())
    # print(bestepoch)
    # test_acc_df.loc[test_acc_df['test_acc'].idxmax()]
    best_epochs.append(best_epoch)

  return best_epochs


if __name__ == '__main__':
  m_Tmultiple = 1
  m_partitions = 10  #partitions of each T = 1
  m_batch_num = 0 #1#2
  m_samples = 6
  m_times = [0,1*m_Tmultiple,5*m_Tmultiple,10*m_Tmultiple]

  # m_model_keys = ['20210225_100858', '20210225_102302','20210225_102435']
  m_model_keys = [
  '20210225_202547',
  '20210225_202830',
  '20210225_202952',
  '20210225_204159',
  '20210225_204315',
  '20210225_205227',
  '20210225_205357',
  '20210225_212529',
  '20210225_212651']


  m_model_epochs = find_best_epoch(m_model_keys)
  # print(f"Best epochs {m_model_epochs}")
  # m_model_epochs = [63,63,63]#[20]#,7]#, 4] #, 63, 63] #, 15, 15]
  m_attention_epochs = [0,1,2,4,7,31,63]

  # build_batches(m_model_keys, m_model_epochs, m_attention_epochs, m_samples, m_Tmultiple, m_partitions, m_batch_num, m_times)

  # times = [1, 5, 10]
  m_times = [1, 3, 6]
  m_samples = 6


  m_model_keys = [['20210225_202547','20210225_202830','20210225_202952'],
                  ['20210225_202547','20210225_204159','20210225_204315'],
                  ['20210225_202547','20210225_205227','20210225_205357'],
                  ['20210225_202547','20210225_212529','20210225_212651']]
  image_folder = ["cosine_sim", "scaled_dot", "cosine_power", "pearson"]

  for i, m_model_keys in enumerate(m_model_keys):
    model_comparison(m_model_keys, m_model_epochs, m_times, image_folder[i], m_samples, m_Tmultiple, m_partitions, m_batch_num)
    model_delta_comparison(m_model_keys, m_model_epochs, m_times, image_folder[i], m_samples, m_Tmultiple, m_partitions, m_batch_num)

  # attention_evolution_old(model_keys, attention_epochs, samples, Tmultiple, partitions, batch_num, times)
  # model_comparison
  # model_keys = ['20210212_101642','20210221_173048','20210218_132704']
  # model_epochs = [63,63,63]

  # model_keys = ['20210222_125239']
  # find_best_epoch(model_keys)